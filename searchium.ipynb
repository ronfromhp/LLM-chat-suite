{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronfromhp/LLM-chat-suite/blob/master/searchium.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiTGVJYjcqfm",
        "outputId": "1f19b7bc-55f2-4026-a612-900706981729"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.22.0-py3-none-any.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.13.0 (from gradio)\n",
            "  Downloading gradio_client-0.13.0-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.20.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.3.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.6.4)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.3.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.10.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.13.0->gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.13.0->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.16.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
            "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.1)\n",
            "Collecting starlette<0.37.0,>=0.36.3 (from fastapi->gradio)\n",
            "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.7)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=869054999a223ca08dfb7176fc04528fb03917867fc362caf781d92937446e62\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, tomlkit, shellingham, semantic-version, ruff, python-multipart, orjson, h11, colorama, aiofiles, uvicorn, starlette, httpcore, httpx, fastapi, gradio-client, gradio\n",
            "Successfully installed aiofiles-23.2.1 colorama-0.4.6 fastapi-0.110.0 ffmpy-0.3.2 gradio-4.22.0 gradio-client-0.13.0 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 orjson-3.9.15 pydub-0.25.1 python-multipart-0.0.9 ruff-0.3.3 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.36.3 tomlkit-0.12.0 uvicorn-0.29.0 websockets-11.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YSqxFXldu8B",
        "outputId": "5a13ac8f-1fd8-4129-c8d2-3bb08eab0400"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n",
            "Installing collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu --no-cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vwc_Uss-vnlf",
        "outputId": "0b77b8a2-750b-4b97-f7b2-a900e7aef10a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.7.3)\n",
            "Collecting gdown\n",
            "  Downloading gdown-5.1.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.7.3\n",
            "    Uninstalling gdown-4.7.3:\n",
            "      Successfully uninstalled gdown-4.7.3\n",
            "Successfully installed gdown-5.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize, InterpolationMode\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Code to convert one video to few images.\n",
        "def video2image(video_path, frame_rate=1.0, size=224):\n",
        "    def preprocess(size, n_px):\n",
        "        return Compose([\n",
        "            Resize(size, interpolation=InterpolationMode.BICUBIC),\n",
        "            CenterCrop(size),\n",
        "            lambda image: image.convert(\"RGB\"),\n",
        "            ToTensor(),\n",
        "            Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),\n",
        "        ])(n_px)\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    cap = cv2.VideoCapture(video_path, cv2.CAP_FFMPEG)\n",
        "    frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    if fps < 1:\n",
        "        images = np.zeros([3, size, size], dtype=np.float32)\n",
        "        print(\"ERROR: problem reading video file: \", video_path)\n",
        "    else:\n",
        "        total_duration = (frameCount + fps - 1) // fps\n",
        "        start_sec, end_sec = 0, total_duration\n",
        "        interval = fps / frame_rate\n",
        "        frames_idx = np.floor(np.arange(start_sec*fps, end_sec*fps, interval))\n",
        "        ret = True\n",
        "        images = np.zeros([len(frames_idx), 3, size, size], dtype=np.float32)\n",
        "\n",
        "        for i, idx in enumerate(frames_idx):\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES , idx)\n",
        "            ret, frame = cap.read()\n",
        "            if not ret: break\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            last_frame = i\n",
        "            images[i,:,:,:] = preprocess(size, Image.fromarray(frame).convert(\"RGB\"))\n",
        "\n",
        "        images = images[:last_frame+1]\n",
        "    cap.release()\n",
        "    video_frames = torch.tensor(images)\n",
        "    return video_frames\n",
        "\n",
        "from transformers import CLIPVisionModelWithProjection\n",
        "\n",
        "model = CLIPVisionModelWithProjection.from_pretrained(\"Searchium-ai/clip4clip-webvid150k\")\n",
        "model = model.eval()\n",
        "\n",
        "def vectorize(video_frames):\n",
        "  visual_output = model(video_frames)\n",
        "  print(visual_output.keys())\n",
        "  # Normalizing the embeddings and calculating mean between all embeddings.\n",
        "  visual_output = visual_output[\"image_embeds\"]\n",
        "  print(visual_output.shape)\n",
        "  visual_output = visual_output / visual_output.norm(dim=-1, keepdim=True)\n",
        "  visual_output = torch.mean(visual_output, dim=0)\n",
        "  visual_output = visual_output / visual_output.norm(dim=-1, keepdim=True)\n",
        "  visual_output = visual_output.detach().numpy()\n",
        "  return visual_output\n"
      ],
      "metadata": {
        "id": "QxdKWqdYkcT9"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "frames = video2image(\"./1.mp4\")\n",
        "print(frames[1].shape)\n",
        "tes = frames[1].unsqueeze(0)\n",
        "vector = model(tes)\n",
        "print(vector)\n",
        "vector = vector[\"image_embeds\"].detach().numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjGMb8jFsXHJ",
        "outputId": "2ac50e9b-0369-4982-fe13-6f19e6b2199f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.mp4  sample_data\n",
            "torch.Size([3, 224, 224])\n",
            "CLIPVisionModelOutput(image_embeds=tensor([[-1.4974e-01,  5.3186e-01,  1.2442e-01,  2.8533e-01,  1.1352e-01,\n",
            "          2.1543e-01,  2.3476e-01,  2.2487e-01, -4.8354e-01, -1.3870e-01,\n",
            "         -2.8904e-01,  2.0953e-01, -2.0154e-01, -4.9852e-01,  2.7907e-01,\n",
            "          3.3918e-02,  2.5178e-01, -2.2977e-01,  3.8322e-02, -3.4921e-01,\n",
            "         -9.1094e-01, -2.5938e-03, -1.9817e-01,  4.1369e-01,  1.4112e-01,\n",
            "          1.4826e-01,  2.0661e-01, -7.1013e-02,  1.0074e-01, -1.9369e-01,\n",
            "         -2.0950e-01,  2.4866e-01, -1.4619e-01, -1.2229e-01,  9.6261e-01,\n",
            "          1.5733e-01,  5.0214e-01, -1.4071e-01,  4.7233e-03,  5.4508e-01,\n",
            "         -4.6900e-02, -4.2841e-01,  1.3472e-01,  1.1329e-01, -2.7920e-01,\n",
            "         -1.0627e+00,  3.2588e-01,  6.4066e-01,  2.8248e-01, -3.6000e-02,\n",
            "         -1.5156e-01,  3.7599e-01,  4.0127e-01, -3.5461e-02, -1.8951e-01,\n",
            "          5.3801e-02,  1.0834e-01,  3.5585e-01,  1.1333e-01,  2.6880e-01,\n",
            "         -7.7335e-01,  2.7875e-01, -2.7918e-02, -3.9439e-01, -1.1941e-01,\n",
            "         -6.8296e-02, -1.1659e-03,  4.7454e-01, -5.1674e-01,  4.1637e-01,\n",
            "          2.3783e-01,  2.7412e-01, -9.6780e-02, -3.4115e-01, -6.2601e-01,\n",
            "          1.2176e-01, -1.6150e-01,  4.1711e-01,  6.4296e-02,  2.6297e-01,\n",
            "         -2.5716e-02,  1.6667e-01, -1.0436e-01,  7.4883e-02,  1.2245e-01,\n",
            "         -1.8204e-01,  1.4440e-01,  2.1919e-01,  1.2029e-01,  1.0523e-01,\n",
            "          6.6919e-02, -2.3457e-01, -4.9505e+00,  4.2020e-01, -3.3147e-01,\n",
            "          1.9855e-01, -3.2014e-01,  8.5706e-02,  6.3445e-01,  1.6652e-02,\n",
            "         -3.7427e-01, -8.5530e-01,  7.8950e-02,  5.1308e-02, -3.8684e-01,\n",
            "          9.6548e-02,  4.2153e-01, -2.3937e-01, -1.1415e-01,  4.6321e-01,\n",
            "          7.0981e-01,  3.6588e-01,  2.9318e-01, -9.2901e-02, -3.3583e-01,\n",
            "          3.9240e-02, -1.7376e-01,  2.8371e-01, -1.0024e-01, -4.3775e-01,\n",
            "          5.0973e-01,  7.8781e-02,  3.9762e-01,  1.8927e-01, -2.4112e-01,\n",
            "         -3.1284e-02,  3.8898e-02, -8.1597e-01, -7.0757e-02, -4.4731e-01,\n",
            "          1.3292e-02, -7.6668e-01, -6.0262e-01,  7.4390e-01, -3.0344e-01,\n",
            "          3.1091e-01,  1.9801e-02, -4.6131e-02, -1.9427e-01, -6.0673e-04,\n",
            "          5.6048e-01, -3.9781e-02, -9.0293e-02,  7.2983e-02, -6.7489e-01,\n",
            "         -2.4964e-01, -3.3555e-01, -2.6278e-01, -3.4843e-03, -9.8181e-02,\n",
            "          2.2128e-01, -9.3995e-02, -3.8293e-01, -2.0352e-01, -2.8048e-01,\n",
            "         -9.7933e-02, -3.4939e-01,  1.5014e-01,  5.7680e-02, -4.0744e-01,\n",
            "          4.6908e-01, -1.4014e-01, -6.7547e-02, -1.1049e-01,  4.7642e-01,\n",
            "         -6.4810e-02,  4.9260e-01,  8.4872e-02,  2.0855e-01, -3.8494e-01,\n",
            "         -8.5312e-02,  1.5105e-03,  1.3419e-01,  1.8790e-01, -4.4105e-02,\n",
            "          6.7609e-01, -5.8404e-01, -3.5231e-01,  5.9644e-01,  7.3433e-02,\n",
            "          4.0346e-01, -3.7733e-01, -8.9325e-01, -3.2565e-01, -1.0685e-01,\n",
            "          1.6260e-01,  2.8065e-01,  2.4413e-01, -3.7566e-01,  2.7002e-01,\n",
            "         -1.8166e-01,  1.6771e-01,  2.9211e-01, -4.0715e-01,  4.7948e-02,\n",
            "         -1.3365e-01, -2.3570e-01,  1.4838e-01, -5.3902e-01,  6.4624e-02,\n",
            "          2.8421e-01,  7.6611e-02, -1.9896e-01,  5.0927e-02, -1.5467e-05,\n",
            "         -9.8547e-02,  2.4522e-01, -3.3843e-02,  4.9569e-01,  2.0914e-02,\n",
            "          4.5930e-01,  4.9667e-01,  6.4827e-03,  1.8841e-01,  8.3764e-01,\n",
            "         -4.2253e-01,  4.5620e-02,  3.3243e-01, -4.9099e-02, -2.7094e-01,\n",
            "          2.7433e-01,  2.9022e-01,  2.7521e-01,  3.3877e-01, -4.3790e-01,\n",
            "         -1.5830e-01,  3.5967e-01,  1.8933e-03, -2.0436e-01,  2.8423e-01,\n",
            "         -2.0806e-01,  1.1736e-01,  1.7561e-01, -3.6928e-01, -4.6201e-01,\n",
            "         -3.6111e-01,  2.2527e-01, -3.7998e-01, -3.3607e-01, -1.6821e-01,\n",
            "          7.1127e-02, -2.5794e-01, -9.8265e-02, -4.5183e-01, -5.3999e-01,\n",
            "          8.8857e-01,  3.8029e-01,  2.3692e-01, -3.6400e-01,  4.8243e-02,\n",
            "          7.5683e-01, -5.0175e-01, -1.6342e-02,  2.2041e-01,  1.5991e-01,\n",
            "          5.2134e-01, -4.0914e-01,  3.6505e-01,  7.2367e-01, -4.6451e-01,\n",
            "         -5.2365e-02,  4.4777e-01, -1.7669e-03,  8.9619e-01, -2.4260e-01,\n",
            "          1.0214e-01, -5.6365e-01,  2.9581e-01, -3.1179e-01, -1.5734e-01,\n",
            "         -2.3702e-01,  1.9857e-01, -2.8371e-01, -1.1608e-01, -3.3535e-01,\n",
            "          1.4637e-01, -1.0337e-02,  1.5031e-01, -1.1339e-01,  4.6327e-02,\n",
            "         -4.1400e-01,  1.8135e-01,  4.1326e-01,  1.3861e-01,  4.1906e-02,\n",
            "          2.6895e-01, -4.7115e-01,  2.0198e-01,  3.2552e-01, -2.0551e-02,\n",
            "          7.7411e-03, -4.9306e-01,  9.5225e-02,  1.4127e-01, -3.2300e-01,\n",
            "          8.4412e-02,  2.3973e-01,  1.3249e-01, -2.6875e-01,  7.4588e-02,\n",
            "          8.7232e-02, -1.1705e-01, -5.1462e-02,  3.7142e-01, -9.7904e-02,\n",
            "          1.7603e-01,  1.0015e-01,  1.3575e-01, -1.4233e-01,  2.8929e-02,\n",
            "          2.4870e-01,  8.9136e-02,  7.4221e-01,  2.5787e-01,  2.0248e-01,\n",
            "          3.8958e-01,  2.6093e-01,  2.1777e-01, -9.7727e-02,  6.9862e-01,\n",
            "          4.2913e-01,  1.0982e+00, -7.8957e-01,  4.8000e-01, -7.0584e-02,\n",
            "          1.4982e-01,  1.1636e-01, -1.9666e-01,  1.6949e-01, -3.0618e-01,\n",
            "          2.1931e-01, -2.8333e-01,  4.0920e-01, -1.6364e-01, -3.6080e-01,\n",
            "          3.0977e-01,  3.0002e-01, -8.0549e-01,  1.8133e-01, -4.9834e-01,\n",
            "         -3.7632e-01,  1.2295e-01, -9.0269e-02, -4.7969e-01, -1.2479e-01,\n",
            "         -8.2295e-03, -2.8339e-01, -1.7995e-01,  7.2733e-02,  4.2640e-01,\n",
            "         -3.9713e-01,  1.8968e-01,  3.5079e-01,  5.8937e-02,  2.8571e-01,\n",
            "         -1.6469e-01,  3.4651e-01,  7.7535e-01,  2.6668e-01,  9.1454e-02,\n",
            "         -1.0909e+00,  4.8529e-01,  1.7144e-01,  2.8455e-02,  1.0216e+00,\n",
            "          3.7901e-01, -6.6565e-02,  2.7490e-01,  3.5433e-02,  1.9946e-01,\n",
            "         -3.6131e-02,  1.4037e-01,  2.6110e-01,  5.6537e-02, -1.3034e-01,\n",
            "          4.6692e-02, -7.5178e-01,  3.9377e-01, -7.3162e-01, -1.8178e-01,\n",
            "         -1.2279e-01, -9.6641e-01, -2.2262e-01, -1.7306e-02,  3.9153e-01,\n",
            "         -5.3004e-01, -1.4796e-01, -4.0903e-01, -8.5877e-01,  5.3652e-01,\n",
            "          5.6429e-01, -2.6834e-02,  2.1446e-01,  3.9008e-02, -1.9979e-01,\n",
            "         -5.2928e-01, -4.6832e-01, -6.6493e-02,  2.4292e-02, -8.4669e-02,\n",
            "          1.8548e-01, -2.1723e-01,  1.1908e+00,  1.0143e-01, -2.2344e-01,\n",
            "         -1.2845e-01,  2.0142e-01,  1.7801e-01, -2.9811e-01, -3.7242e-01,\n",
            "          1.1612e-02, -5.2178e-01,  6.7650e-02,  2.5442e-01, -1.9716e-01,\n",
            "         -3.7649e-01,  3.3476e-01, -2.3724e-02, -2.2403e-01, -1.3314e-01,\n",
            "          1.4689e-01,  4.7254e-01,  1.6171e-01, -7.8292e-02, -4.0784e-01,\n",
            "          4.1153e-01, -5.7778e-01, -1.7409e-01, -4.3593e-01,  5.8116e-01,\n",
            "         -2.6231e-02,  6.7082e-01,  2.0357e-01,  2.3158e-02,  1.9383e-02,\n",
            "         -4.0623e-01, -7.6643e-01, -5.7602e-02, -1.8733e-01, -1.4805e-01,\n",
            "          1.1401e-01,  2.5885e-01,  4.4672e-01,  2.9821e-01,  4.2207e-01,\n",
            "         -6.8829e-02,  1.9131e-01, -1.2786e-01, -1.6720e-01,  5.8764e-01,\n",
            "          2.2029e-01, -2.6394e-01, -4.6362e-01,  7.1802e-01, -7.7556e-01,\n",
            "          5.8003e-01,  3.0147e-01,  5.3165e-01, -8.8989e-02,  7.1301e-02,\n",
            "          2.5955e-01, -2.6081e-01,  1.7647e-01, -6.9507e-02, -7.6380e-02,\n",
            "          4.7893e-02,  6.1464e-01,  4.9112e-02,  5.1594e-01, -5.7945e-01,\n",
            "         -3.4035e-01,  3.9348e-01,  1.7844e-01,  2.5900e-01, -2.2583e-01,\n",
            "         -5.1744e-01,  3.4461e-01, -1.5007e-03,  2.2870e-01,  4.2188e-03,\n",
            "         -1.8236e-01, -7.9903e-02,  3.6607e-01,  3.2661e-01,  1.3019e-01,\n",
            "         -3.4997e-01,  3.1053e-02,  4.3723e-01, -3.5164e-01,  2.6565e-01,\n",
            "          2.6977e-03,  3.9279e-02, -4.0074e-01, -2.1702e-01,  3.9082e-02,\n",
            "          3.3248e-01,  2.6504e-01, -3.6111e-01, -5.7874e-02,  2.2180e-01,\n",
            "         -2.6517e-01,  1.4387e-01, -2.8778e-02, -1.0094e-01,  5.6202e-01,\n",
            "         -1.3415e-01,  1.6000e-01,  3.9411e-01,  5.5399e-01, -3.5696e-01,\n",
            "         -3.5093e-01, -1.9495e-01]], grad_fn=<MmBackward0>), last_hidden_state=tensor([[[-0.2014,  0.1106, -0.2174,  ...,  0.2292,  0.5125, -0.2759],\n",
            "         [ 0.0798,  0.4625, -0.3650,  ..., -0.0108,  0.7460,  0.5496],\n",
            "         [ 0.5969,  0.8145, -0.3664,  ...,  0.0048,  0.8607,  0.1945],\n",
            "         ...,\n",
            "         [ 0.2905,  0.8972,  0.3309,  ...,  0.5033,  0.5486, -0.0852],\n",
            "         [ 0.2823,  0.6354,  0.3138,  ...,  0.4350,  0.3459,  0.0581],\n",
            "         [ 0.5693,  0.1565, -0.4281,  ...,  0.2962,  0.3025,  0.4543]]],\n",
            "       grad_fn=<AddBackward0>), hidden_states=None, attentions=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "def visualize_feature(feature_vector):\n",
        "    # Reshape the feature vector to a 2D array if needed\n",
        "    # feature_vector = feature_vector.reshape(1, -1)\n",
        "    print(feature_vector.shape)\n",
        "    # Apply t-SNE to reduce the dimensionality to 2D\n",
        "    tsne = TSNE(n_components=2, random_state=42)\n",
        "    feature_2d = tsne.fit_transform(feature_vector)\n",
        "\n",
        "    # Plot the feature in a 2D scatter plot\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.scatter(feature_2d[:, 0], feature_2d[:, 1])\n",
        "    plt.xlabel('t-SNE Dimension 1')\n",
        "    plt.ylabel('t-SNE Dimension 2')\n",
        "    plt.title('Feature Visualization')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "visualize_feature(vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "C808ZnLXt65e",
        "outputId": "1e091a11-083d-4a16-91c4-445d7883bf33"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 512)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "perplexity must be less than n_samples",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-077a93c7b4b2>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mvisualize_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-45-077a93c7b4b2>\u001b[0m in \u001b[0;36mvisualize_feature\u001b[0;34m(feature_vector)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Apply t-SNE to reduce the dimensionality to 2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mfeature_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Plot the feature in a 2D scatter plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \"\"\"\n\u001b[1;32m   1117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1118\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params_vs_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1119\u001b[0m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36m_check_params_vs_input\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_params_vs_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperplexity\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"perplexity must be less than n_samples\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_num_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: perplexity must be less than n_samples"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "dYSYXCQOnwu2",
        "outputId": "3b85f13b-99dd-4243-9a0d-d2e19624e472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/parse_url.py:44: UserWarning: You specified a Google Drive link that is not the correct link to download a file. You might want to try `--fuzzy` option or the following url: https://drive.google.com/uc?id=1tAr73sFIIu690-AVsu1rvftTLfWKStXK\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/file/d/1tAr73sFIIu690-AVsu1rvftTLfWKStXK/view?usp=drive_link\n",
            "To: /content/1.mp4\n",
            "81.9kB [00:00, 154MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./1.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import gdown\n",
        "import os\n",
        "def download_video(gdrive_url, output):\n",
        "    if not os.path.exists(output):\n",
        "        try:\n",
        "          gdown.download(gdrive_url, output)\n",
        "        except:\n",
        "          return output\n",
        "    return output\n",
        "\n",
        "download_video(\"https://drive.google.com/file/d/1tAr73sFIIu690-AVsu1rvftTLfWKStXK/view?usp=drive_link\", \"./1.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_video_vectors(dataset_csv):\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(dataset_csv)\n",
        "\n",
        "    # Initialize an empty list to store video vectors\n",
        "    video_vectors = []\n",
        "\n",
        "    # Iterate over each row in the CSV file\n",
        "    for index, row in df.iterrows():\n",
        "        # Get the Google Drive URL of the video\n",
        "        gdrive_url = row['contentUrl']\n",
        "\n",
        "        # Download the video\n",
        "        video_path = download_video(gdrive_url, f'videos/{index}.mp4')\n",
        "\n",
        "        # Convert the video to frames\n",
        "        video_frames = video2image(video_path)\n",
        "\n",
        "        # Generate the vector for the video frames\n",
        "        video_vector = vectorize(video_frames)\n",
        "\n",
        "        # Append the video vector to the list\n",
        "        video_vectors.append(video_vector)\n",
        "\n",
        "        print(f'Processed video {index + 1}/{len(df)}')\n",
        "\n",
        "    # Convert the list of video vectors to a NumPy array\n",
        "    video_vectors = np.array(video_vectors)\n",
        "\n",
        "    # Save the video vectors to a file\n",
        "    np.save('visual_feats.np', video_vectors)\n",
        "\n",
        "    print('Video vectors saved to visual_feats.np')"
      ],
      "metadata": {
        "id": "8ITP-I74n8KM"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "\n",
        "def generate_video_dataset(folder_id, api_key, output_file):\n",
        "    # Create a Google Drive API service\n",
        "    service = build('drive', 'v3', developerKey=api_key)\n",
        "\n",
        "    # Retrieve the list of files in the folder\n",
        "    query = f\"'{folder_id}' in parents and trashed = false\"\n",
        "    results = service.files().list(q=query, fields=\"nextPageToken, files(id, name, mimeType)\").execute()\n",
        "    files = results.get('files', [])\n",
        "\n",
        "    # Initialize empty lists to store video names and URLs\n",
        "    video_names = []\n",
        "    video_urls = []\n",
        "\n",
        "    # Iterate over each video file in the folder\n",
        "    for file in files:\n",
        "        if file['mimeType'].startswith('video/'):\n",
        "            video_names.append(file['name'])\n",
        "            video_urls.append(f\"https://drive.google.com/uc?id={file['id']}\")\n",
        "\n",
        "    # Create a DataFrame with video names and URLs\n",
        "    df = pd.DataFrame({'filename': video_names, 'contentUrl': video_urls})\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    df.to_csv(output_file, index=False)\n",
        "\n",
        "    print(f\"Dataset file '{output_file}' generated with {len(df)} videos.\")\n",
        "\n",
        "generate_video_dataset(folder_id= \"1-1IaC5R1t6F4PQZ8QSAqnR-iODupP1lk\", api_key=\"AIzaSyCf14Ppn5dJUG37VfHHdHzSY-y1WtMP42w\", output_file= \"letssee.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efKgtfmMuQ4M",
        "outputId": "2016dd5b-c4b1-4369-cfe3-b3c876ac4700"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset file 'letssee.csv' generated with 100 videos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_video_vectors(\"letssee.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Z0-BMQ-wo9Qi",
        "outputId": "9ee9d73f-3b11-4fa7-a4a5-918804c1c652"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 1/100\n",
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 2/100\n",
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 3/100\n",
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 4/100\n",
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 5/100\n",
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 6/100\n",
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 7/100\n",
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 8/100\n",
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 9/100\n",
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 10/100\n",
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 11/100\n",
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 12/100\n",
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 13/100\n",
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 14/100\n",
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 15/100\n",
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 16/100\n",
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 17/100\n",
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 18/100\n",
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 19/100\n",
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 20/100\n",
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 21/100\n",
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 22/100\n",
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 23/100\n",
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 24/100\n",
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 25/100\n",
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 26/100\n",
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 27/100\n",
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 28/100\n",
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 29/100\n",
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 30/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1KkVPTNyKQS5Id7Pe2WMxVVlhI7fruubi\n",
            "To: /content/videos/30.mp4\n",
            "100%|██████████| 13.2M/13.2M [00:00<00:00, 35.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 31/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1AN0nYt1BBjwfMMQgLRq0KRBdMBgqOVOd\n",
            "To: /content/videos/31.mp4\n",
            "100%|██████████| 12.9M/12.9M [00:00<00:00, 50.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 32/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1yFukfaaa0CGBz_o2oM-fFg1-lMUU9tES\n",
            "To: /content/videos/32.mp4\n",
            "100%|██████████| 11.2M/11.2M [00:00<00:00, 26.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 33/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qNiLEX7IDWubbKOiGeh6bXDpn0PnAzma\n",
            "To: /content/videos/33.mp4\n",
            "100%|██████████| 12.7M/12.7M [00:00<00:00, 30.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 34/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=17FjKYHofPoU1kguuf5EsH76XDCsQIeZI\n",
            "To: /content/videos/34.mp4\n",
            "100%|██████████| 12.7M/12.7M [00:00<00:00, 28.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 35/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_GgRYj0smNAIX8zcJ20Lbxkq4kDH-t-w\n",
            "To: /content/videos/35.mp4\n",
            "100%|██████████| 12.5M/12.5M [00:00<00:00, 33.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 36/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1KyTIaLw3GLlEwAsIdA1M4mYJ5Rla0aJJ\n",
            "To: /content/videos/36.mp4\n",
            "100%|██████████| 12.5M/12.5M [00:00<00:00, 26.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 37/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19Q7xjGu9Vf9hl11ulcrg1zziaGt398bR\n",
            "To: /content/videos/37.mp4\n",
            "100%|██████████| 12.4M/12.4M [00:00<00:00, 32.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 38/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=14kpBenUSE1vrQDQhApVf_v3IsfPgXn6Y\n",
            "To: /content/videos/38.mp4\n",
            "100%|██████████| 12.4M/12.4M [00:00<00:00, 46.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 39/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1c6VskmNfQceKSpOUExmS9_0T4KAmTPw6\n",
            "To: /content/videos/39.mp4\n",
            "100%|██████████| 12.3M/12.3M [00:00<00:00, 22.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 40/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CHuD2KmFSyaVjpVKbSz-yCkVQzSBQ25H\n",
            "To: /content/videos/40.mp4\n",
            "100%|██████████| 12.3M/12.3M [00:00<00:00, 28.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 41/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Dh9ngVP-hVrQASykxjkddloAOuUWyLKr\n",
            "To: /content/videos/41.mp4\n",
            "100%|██████████| 12.5M/12.5M [00:00<00:00, 27.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 42/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19Qw6Jag9_tfPvQ8vKFYds4TSu_61JhWr\n",
            "To: /content/videos/42.mp4\n",
            "100%|██████████| 12.2M/12.2M [00:00<00:00, 32.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 43/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1dms-Dn7c4z33mGn7zT9Io5LirB4bda6I\n",
            "To: /content/videos/43.mp4\n",
            "100%|██████████| 9.81M/9.81M [00:00<00:00, 27.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 44/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1fmJMDjH5NNY2w_jTM8SKI6rcVkIAaEtc\n",
            "To: /content/videos/44.mp4\n",
            "100%|██████████| 12.1M/12.1M [00:00<00:00, 49.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 45/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1t66scWRPYLdiuPHSGdoRA4eh13F6_ARl\n",
            "To: /content/videos/45.mp4\n",
            "100%|██████████| 8.95M/8.95M [00:00<00:00, 25.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 46/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15VKCF0qCmr_Vop3p-3RvJ8LG5m1zdARY\n",
            "To: /content/videos/46.mp4\n",
            "100%|██████████| 11.9M/11.9M [00:00<00:00, 30.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 47/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=17Bm3_ihW6LGsFdg9NWr_unvNwqDbKtAg\n",
            "To: /content/videos/47.mp4\n",
            "100%|██████████| 11.8M/11.8M [00:00<00:00, 32.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 48/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1wsd3s_lg65Gbl7t5KDnKh4xE0StTvzkc\n",
            "To: /content/videos/48.mp4\n",
            "100%|██████████| 11.8M/11.8M [00:00<00:00, 32.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 49/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Rpr0NIy7G_UTOlLPjAU_ArbnFMhaokVX\n",
            "To: /content/videos/49.mp4\n",
            "100%|██████████| 11.5M/11.5M [00:00<00:00, 31.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 50/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=14vkbe5tXMa13FQ--XEIGL32U_0T1jl14\n",
            "To: /content/videos/50.mp4\n",
            "100%|██████████| 11.8M/11.8M [00:00<00:00, 32.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 51/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JKgkXDC86n9GZCueVgwAtfQbiouB_KJi\n",
            "To: /content/videos/51.mp4\n",
            "100%|██████████| 11.7M/11.7M [00:00<00:00, 32.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 52/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ffnq-Ft3iaF1_YgzqGEmUaYcwrVyS74N\n",
            "To: /content/videos/52.mp4\n",
            "100%|██████████| 11.7M/11.7M [00:00<00:00, 32.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 53/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1lV0fEviJZ1thfhrkRk_rdgXBwjgtATJy\n",
            "To: /content/videos/53.mp4\n",
            "100%|██████████| 11.7M/11.7M [00:00<00:00, 54.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 54/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1GG7yn9xcqjxB9IngbpcdaOhtO_7HyoP1\n",
            "To: /content/videos/54.mp4\n",
            "100%|██████████| 11.5M/11.5M [00:00<00:00, 52.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 55/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1P6mMlORckyrp7oKBh5xs7w6XWpytA88C\n",
            "To: /content/videos/55.mp4\n",
            "100%|██████████| 11.3M/11.3M [00:00<00:00, 31.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 56/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1if5RTRI6HFGZiizapnktVjrkSLbeP7EN\n",
            "To: /content/videos/56.mp4\n",
            "100%|██████████| 11.3M/11.3M [00:00<00:00, 48.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 57/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1f4cweiVlZ14t_htVgYGmHWii59WHu4tQ\n",
            "To: /content/videos/57.mp4\n",
            "100%|██████████| 11.2M/11.2M [00:00<00:00, 53.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 58/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ebCYPB6g0A5wNzybOhUhP_deV65MlyKY\n",
            "To: /content/videos/58.mp4\n",
            "100%|██████████| 11.2M/11.2M [00:00<00:00, 22.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 59/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1C1WuUUYnJHC_QDipcF2GFaoQ7jNNH2DN\n",
            "To: /content/videos/59.mp4\n",
            "100%|██████████| 11.1M/11.1M [00:00<00:00, 46.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 60/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Jp_8CjLr-QZsNlwJMsrJohR_6zIw0MmD\n",
            "To: /content/videos/60.mp4\n",
            "100%|██████████| 11.1M/11.1M [00:00<00:00, 18.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 61/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1h118VnqEcD1BiB3So_qepUgRi_UnRSrd\n",
            "To: /content/videos/61.mp4\n",
            "100%|██████████| 11.0M/11.0M [00:00<00:00, 47.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['image_embeds', 'last_hidden_state'])\n",
            "Processed video 62/100\n",
            "ERROR: problem reading video file:  videos/62.mp4\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Sizes of tensors must match except in dimension 1. Expected size 3 but got size 768 for tensor number 1 in the list.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-27fe89baa8bf>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_video_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"letssee.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-31-172712dc28af>\u001b[0m in \u001b[0;36mgenerate_video_vectors\u001b[0;34m(dataset_csv)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Generate the vector for the video frames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mvideo_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Append the video vector to the list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-79bb3f1d3664>\u001b[0m in \u001b[0;36mvectorize\u001b[0;34m(video_frames)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0mvisual_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisual_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0;31m# Normalizing the embeddings and calculating mean between all embeddings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/clip/modeling_clip.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, pixel_values, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         vision_outputs = self.vision_model(\n\u001b[0m\u001b[1;32m   1297\u001b[0m             \u001b[0mpixel_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpixel_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/clip/modeling_clip.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, pixel_values, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    847\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You have to specify pixel_values\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 849\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixel_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    850\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_layrnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/clip/modeling_clip.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, pixel_values)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mclass_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_embeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_embeds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 3 but got size 768 for tensor number 1 in the list."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqe3JMrQcfbD",
        "outputId": "1eb72136-881e-4c7d-c3c7-6c30e6875e83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://733fe45da6253ceb06.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython import display\n",
        "import faiss\n",
        "import torch\n",
        "from transformers import CLIPTokenizer, CLIPTextModelWithProjection\n",
        "\n",
        "HTML=\"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "    <style>\n",
        "    .container {\n",
        "        align-items: center;\n",
        "        justify-content: center;\n",
        "    }\n",
        "\n",
        "    img {\n",
        "        max-width: 10%;\n",
        "        max-height:10%;\n",
        "        float: left;\n",
        "    }\n",
        "\n",
        "    .text {\n",
        "        font-size: 32px;\n",
        "        padding-top: 15%;\n",
        "        padding-left: 15%;\n",
        "        padding-bottom: 5%;\n",
        "        float: left\n",
        "    }\n",
        "    </style>\n",
        "    <body>\n",
        "        <div class=\"container\">\n",
        "            <div class=\"image\">\n",
        "                <img src=\"https://huggingface.co/spaces/Searchium-ai/Video-Search/resolve/main/Searchium.png\" width=\"333\" height=\"216\">\n",
        "            </div>\n",
        "            <div class=\"text\">\n",
        "                <h1 style=\"font-size: 32px;\"><b> Large Scale Video Search </b></h1>\n",
        "            </div>\n",
        "        </div>\n",
        "    </body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "DESCRIPTION=\"\"\"<b> Exciting News! </b> <br>\n",
        "               <b> We've added another 4 million video embeddings to our collection! </b> <br>\n",
        "\n",
        "\n",
        "               Welcome to our video retrieval demo powered by [Searchium-ai/clip4clip-webvid150k](https://huggingface.co/Searchium-ai/clip4clip-webvid150k)! <br>\n",
        "               Using free text search - you will find the top 5 most relevant clips among a dataset of <b> 5.5 million </b> video clips. <br>\n",
        "               Discover, explore, and enjoy the world of video search at your fingertips.\n",
        "               \"\"\"\n",
        "ENDING = \"\"\"For search acceleration capabilities, please refer to [Searchium.ai](https://www.searchium.ai)\n",
        "            \"\"\"\n",
        "\n",
        "\n",
        "DATA_PATH = './data'\n",
        "\n",
        "ft_visual_features_file = DATA_PATH + '/visual_feats.npy'\n",
        "ft_visual_features_file_bin = DATA_PATH + '/video_half_dataset_visual_features_binary_packed.npy'\n",
        "\n",
        "#load database features:\n",
        "# ft_visual_features_database_bin = np.load(ft_visual_features_file_bin)\n",
        "ft_visual_features_database = np.load(ft_visual_features_file, mmap_mode='r')\n",
        "\n",
        "\n",
        "database_csv_path = os.path.join(DATA_PATH, 'video_dataset.csv')\n",
        "database_df = pd.read_csv(database_csv_path)\n",
        "\n",
        "class NearestNeighbors:\n",
        "    \"\"\"\n",
        "    Class for NearestNeighbors.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_neighbors=10, metric='cosine', rerank_from=-1):\n",
        "        \"\"\"\n",
        "         metric = 'cosine' / 'binary'\n",
        "         if metric ~= 'cosine' and rerank_from > n_neighbors then a cosine rerank will be performed\n",
        "        \"\"\"\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.metric = metric\n",
        "        self.rerank_from = rerank_from\n",
        "\n",
        "    def normalize(self, a):\n",
        "        return a / np.sum(a**2, axis=1, keepdims=True)\n",
        "\n",
        "    def fit(self, data, o_data=None):\n",
        "        if self.metric == 'cosine':\n",
        "            data = self.normalize(data)\n",
        "            self.index = faiss.IndexFlatIP(data.shape[1])\n",
        "        elif self.metric == 'binary':\n",
        "            self.o_data = data if o_data is None else o_data\n",
        "            #assuming data already packed\n",
        "            self.index = faiss.IndexBinaryFlat(data.shape[1]*8)\n",
        "        self.index.add(np.ascontiguousarray(data))\n",
        "\n",
        "    def kneighbors(self, q_data):\n",
        "        if self.metric == 'cosine':\n",
        "            q_data = self.normalize(q_data)\n",
        "            sim, idx = self.index.search(q_data, self.n_neighbors)\n",
        "        else:\n",
        "            if self.metric == 'binary':\n",
        "                print('This is binary search.')\n",
        "                bq_data = np.packbits((q_data > 0.0).astype(bool), axis=1)\n",
        "            sim, idx = self.index.search(bq_data, max(self.rerank_from, self.n_neighbors))\n",
        "\n",
        "            if self.rerank_from > self.n_neighbors:\n",
        "                re_sims = np.zeros([len(q_data), self.n_neighbors], dtype=float)\n",
        "                re_idxs = np.zeros([len(q_data), self.n_neighbors], dtype=float)\n",
        "                for i, q in enumerate(q_data):\n",
        "                    rerank_data = self.o_data[idx[i]]\n",
        "                    rerank_search = NearestNeighbors(n_neighbors=self.n_neighbors, metric='cosine')\n",
        "                    rerank_search.fit(rerank_data)\n",
        "                    re_sim, re_idx = rerank_search.kneighbors(np.asarray([q]))\n",
        "                    print(\"re_idx: \", re_idx)\n",
        "                    re_sims[i, :] = re_sim\n",
        "                    re_idxs[i, :] = idx[i][re_idx]\n",
        "                idx = re_idxs\n",
        "                sim = re_sims\n",
        "\n",
        "        return sim, idx\n",
        "\n",
        "\n",
        "model = CLIPTextModelWithProjection.from_pretrained(\"Searchium-ai/clip4clip-webvid150k\")\n",
        "tokenizer = CLIPTokenizer.from_pretrained(\"Searchium-ai/clip4clip-webvid150k\")\n",
        "\n",
        "nn_search = NearestNeighbors(n_neighbors=5, metric='cosine', rerank_from=100)\n",
        "nn_search.fit(ft_visual_features_database, o_data=ft_visual_features_database)\n",
        "\n",
        "def search(search_sentence):\n",
        "    inputs = tokenizer(text=search_sentence , return_tensors=\"pt\")\n",
        "    outputs = model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n",
        "\n",
        "    # Normalizing the embeddings:\n",
        "    final_output = outputs[0] / outputs[0].norm(dim=-1, keepdim=True)\n",
        "    sequence_output = final_output.cpu().detach().numpy()\n",
        "\n",
        "    sims, idxs = nn_search.kneighbors(sequence_output)\n",
        "    print(idxs)\n",
        "    print()\n",
        "    urls = database_df.iloc[idxs[0]]['contentUrl'].to_list()\n",
        "    print(urls)\n",
        "    AUTOPLAY_VIDEOS = []\n",
        "    i= 0\n",
        "    for url in urls:\n",
        "        download_video(url, str(idxs[0][i])+\".mp4\")\n",
        "        AUTOPLAY_VIDEOS.append(str(idxs[0][i])+\".mp4\")\n",
        "        i+=1\n",
        "    return AUTOPLAY_VIDEOS\n",
        "\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Default(spacing_size=gr.themes.sizes.spacing_lg, radius_size=gr.themes.sizes.radius_lg, text_size=gr.themes.sizes.text_lg)) as demo:\n",
        "    gr.HTML(HTML)\n",
        "    gr.Markdown(DESCRIPTION)\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            inp = gr.Textbox(placeholder=\"Write a sentence.\")\n",
        "            btn = gr.Button(value=\"Search\")\n",
        "            ex = [[\"natural wonders of the world\"],[\"yoga routines for morning energy\"],\n",
        "                [\"baking chocolate cake\"],[\"birds fly in the sky\"]]\n",
        "            gr.Examples(examples=ex,\n",
        "                        inputs=[inp]\n",
        "                        )\n",
        "        with gr.Column():\n",
        "            out = [gr.Video() for _ in range(5)]\n",
        "    btn.click(search, inputs=inp, outputs=out)\n",
        "    gr.Markdown(ENDING)\n",
        "\n",
        "demo.launch(debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyMeIlLmME4sRBMxMEMRjx",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}